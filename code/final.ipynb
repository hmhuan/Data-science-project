{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hawliet/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/cars/train_data.csv\", sep = \"\\t\", encoding='utf-8')\n",
    "test = pd.read_csv(\"../data/cars/test_data.csv\", sep = \"\\t\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['price']\n",
    "test_y = test['price']\n",
    "X = train.drop(['price'], axis = 1)\n",
    "test_X = test.drop(['price'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilabel Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, l):\n",
    "    if type(x) is list:\n",
    "        l.update(x)\n",
    "class MultilabelEncoding(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col_name):\n",
    "        self.col_name = col_name\n",
    "        self.type_list = set()\n",
    "    def fit(self, X_df, y=None):\n",
    "        types_sr = X_df[self.col_name].str.replace('[/+]', ' ').str.split()\n",
    "        types_sr.apply(f, args=(self.type_list,))\n",
    "        self.type_list = list(self.type_list)\n",
    "        return self\n",
    "    def transform(self, X_df, y=None):\n",
    "        transformed_df = X_df.copy()\n",
    "        for i in range(len(self.type_list)):\n",
    "            transformed_df[self.col_name + '_' + self.type_list[i]] = transformed_df[self.col_name].apply(lambda x: 1 if ((type(x) is str) and (self.type_list[i] in x)) else 0)\n",
    "        transformed_df.drop(self.col_name, axis=1, inplace=True)\n",
    "        return transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### col add and drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColAdderDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_top_brands = 10):\n",
    "        # TODO\n",
    "        self.num_top_brands = num_top_brands\n",
    "        self.dropped_cols = ['url', 'name', 'model', 'weightTotal', 'fuelType', 'vehicleTransmission', 'modelDate']\n",
    "    def fit(self, X_df, y=None):\n",
    "        brand_col = X_df.brand.str.extract(r'([a-zA-z]+)', expand=False)\n",
    "        self.brand_counts_ = brand_col.value_counts()\n",
    "        brands = list(self.brand_counts_.index)\n",
    "        self.top_brands_ = brands[:max(1, min(self.num_top_brands, len(brands)))]\n",
    "        return self\n",
    "    def transform(self, X_df, y=None):\n",
    "        df = X_df.copy()\n",
    "        brand_col = df.brand.str.extract(\"([a-zA-z]+)\", expand=False)\n",
    "        brand_col[~brand_col.isin(self.top_brands_)] = 'Others'\n",
    "        df[\"brand\"] = brand_col\n",
    "        df.drop(self.dropped_cols, axis=1, inplace=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_multi = ['vEfuelType', 'driveWheelConfiguration']\n",
    "cat_single = ['brand', 'eLabel', 'bodyType', 'vEengineType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_adderdropper = ColAdderDropper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = []\n",
    "for col in X.columns:\n",
    "    if (not col in cat_single) and (not col in cat_multi) and (not col in col_adderdropper.dropped_cols):\n",
    "        num_cols.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hàm train và validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_val(full_pipeline, train_X, train_y, val_X, val_y):\n",
    "    full_pipeline.fit(train_X, train_y);\n",
    "    #print(\"n_brands:\", len(col_adderdropper.top_brands_))\n",
    "    pred_y = full_pipeline.predict(val_X)\n",
    "    train_score = full_pipeline.score(train_X, train_y)\n",
    "    val_score = full_pipeline.score(val_X, val_y)\n",
    "    print(train_score, val_score)\n",
    "    print(\"MSE =\", np.round(np.mean((pred_y - val_y) ** 2), 3))\n",
    "    print(\"MAE =\", np.round(np.mean(np.abs(pred_y - val_y)), 3))\n",
    "    return train_score, val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### các pipeline cần thiết cho pipeline cho preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(strategy='mean') \n",
    "imp_mode = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "encoding = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "vEfuelType_encoder = MultilabelEncoding('vEfuelType')\n",
    "driveWheelConfig_encoder = MultilabelEncoding('driveWheelConfiguration')\n",
    "\n",
    "categorical_transformer = make_pipeline(imp_mode, encoding)\n",
    "\n",
    "colTransform = ColumnTransformer(transformers=[('numerical', imp_mean, num_cols),\\\n",
    "                                               ('categorical', categorical_transformer, cat_single),\n",
    "                                               ('vEfuelType', vEfuelType_encoder, ['vEfuelType']),\n",
    "                                               ('driveWheelConfig', driveWheelConfig_encoder, ['driveWheelConfiguration'])])\n",
    "\n",
    "colNormalize = StandardScaler()\n",
    "\n",
    "#preprocessing = make_pipeline(col_adderdropper, colTransform, colNormalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Full pipeline với MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 98.19971331\n",
      "Validation score: 0.694891\n",
      "Iteration 2, loss = 45.39279857\n",
      "Validation score: 0.890794\n",
      "Iteration 3, loss = 35.74153083\n",
      "Validation score: 0.919243\n",
      "Iteration 4, loss = 33.95217416\n",
      "Validation score: 0.935488\n",
      "Iteration 5, loss = 32.16732118\n",
      "Validation score: 0.940387\n",
      "Iteration 6, loss = 27.45952570\n",
      "Validation score: 0.943076\n",
      "Iteration 7, loss = 27.50694067\n",
      "Validation score: 0.933659\n",
      "Iteration 8, loss = 23.51543182\n",
      "Validation score: 0.945654\n",
      "Iteration 9, loss = 23.85213672\n",
      "Validation score: 0.946339\n",
      "Iteration 10, loss = 21.13878786\n",
      "Validation score: 0.925930\n",
      "Iteration 11, loss = 28.39498006\n",
      "Validation score: 0.958330\n",
      "Iteration 12, loss = 19.60875726\n",
      "Validation score: 0.963816\n",
      "Iteration 13, loss = 18.06010007\n",
      "Validation score: 0.964053\n",
      "Iteration 14, loss = 17.97257090\n",
      "Validation score: 0.956668\n",
      "Iteration 15, loss = 19.09140831\n",
      "Validation score: 0.906418\n",
      "Iteration 16, loss = 18.29493092\n",
      "Validation score: 0.966422\n",
      "Iteration 17, loss = 16.36221133\n",
      "Validation score: 0.967486\n",
      "Iteration 18, loss = 13.73809579\n",
      "Validation score: 0.965623\n",
      "Iteration 19, loss = 15.34952840\n",
      "Validation score: 0.966659\n",
      "Iteration 20, loss = 16.42998863\n",
      "Validation score: 0.972281\n",
      "Iteration 21, loss = 15.27481690\n",
      "Validation score: 0.957463\n",
      "Iteration 22, loss = 15.66235755\n",
      "Validation score: 0.963024\n",
      "Iteration 23, loss = 13.36307886\n",
      "Validation score: 0.955013\n",
      "Iteration 24, loss = 12.48800054\n",
      "Validation score: 0.971652\n",
      "Iteration 25, loss = 11.86569368\n",
      "Validation score: 0.972592\n",
      "Iteration 26, loss = 13.75762968\n",
      "Validation score: 0.959508\n",
      "Iteration 27, loss = 14.11718525\n",
      "Validation score: 0.968329\n",
      "Iteration 28, loss = 13.11754329\n",
      "Validation score: 0.974469\n",
      "Iteration 29, loss = 12.43489913\n",
      "Validation score: 0.956227\n",
      "Iteration 30, loss = 11.81332916\n",
      "Validation score: 0.955125\n",
      "Iteration 31, loss = 14.91771806\n",
      "Validation score: 0.961356\n",
      "Iteration 32, loss = 13.21616435\n",
      "Validation score: 0.960510\n",
      "Iteration 33, loss = 10.90860128\n",
      "Validation score: 0.973927\n",
      "Iteration 34, loss = 10.23241199\n",
      "Validation score: 0.970021\n",
      "Iteration 35, loss = 10.45965555\n",
      "Validation score: 0.976053\n",
      "Iteration 36, loss = 11.03219061\n",
      "Validation score: 0.972172\n",
      "Iteration 37, loss = 12.50771037\n",
      "Validation score: 0.972234\n",
      "Iteration 38, loss = 11.25198637\n",
      "Validation score: 0.974118\n",
      "Iteration 39, loss = 10.24564329\n",
      "Validation score: 0.975985\n",
      "Iteration 40, loss = 11.45679861\n",
      "Validation score: 0.974635\n",
      "Iteration 41, loss = 12.50415278\n",
      "Validation score: 0.974445\n",
      "Iteration 42, loss = 9.93215773\n",
      "Validation score: 0.976423\n",
      "Iteration 43, loss = 9.64713735\n",
      "Validation score: 0.974986\n",
      "Iteration 44, loss = 9.73011951\n",
      "Validation score: 0.974644\n",
      "Iteration 45, loss = 9.82048655\n",
      "Validation score: 0.964731\n",
      "Iteration 46, loss = 9.60906265\n",
      "Validation score: 0.975698\n",
      "Iteration 47, loss = 9.22392393\n",
      "Validation score: 0.974577\n",
      "Iteration 48, loss = 10.95441229\n",
      "Validation score: 0.977110\n",
      "Iteration 49, loss = 10.90603982\n",
      "Validation score: 0.960522\n",
      "Iteration 50, loss = 11.11134728\n",
      "Validation score: 0.978646\n",
      "Iteration 51, loss = 11.32824406\n",
      "Validation score: 0.977693\n",
      "Iteration 52, loss = 9.00893267\n",
      "Validation score: 0.976239\n",
      "Iteration 53, loss = 9.12757953\n",
      "Validation score: 0.977832\n",
      "Iteration 54, loss = 9.73927720\n",
      "Validation score: 0.977772\n",
      "Iteration 55, loss = 8.77146293\n",
      "Validation score: 0.978331\n",
      "Iteration 56, loss = 9.54546309\n",
      "Validation score: 0.977747\n",
      "Iteration 57, loss = 8.97623495\n",
      "Validation score: 0.975075\n",
      "Iteration 58, loss = 10.02567397\n",
      "Validation score: 0.976558\n",
      "Iteration 59, loss = 8.73046737\n",
      "Validation score: 0.978500\n",
      "Iteration 60, loss = 8.68332670\n",
      "Validation score: 0.978183\n",
      "Iteration 61, loss = 8.93803570\n",
      "Validation score: 0.976446\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.9823796724995534 0.9750759410460554\n",
      "MSE = 23.068\n",
      "MAE = 2.555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9823796724995534, 0.9750759410460554)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_n_brands = 80\n",
    "mlpregressor = MLPRegressor(hidden_layer_sizes=(256, 512, 512, 256, ), solver='adam', learning_rate='adaptive'\\\n",
    "                            ,random_state=0, max_iter=500, early_stopping=True, verbose=1)\n",
    "full_pipeline = make_pipeline(col_adderdropper, colTransform, colNormalize, mlpregressor)\n",
    "full_pipeline.set_params(coladderdropper__num_top_brands=best_n_brands)\n",
    "train_and_val(full_pipeline, X, y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nn_80_final.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(full_pipeline, 'nn_80_final.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full pipeline với RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1024 out of 1024 | elapsed: 40.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1024 out of 1024 | elapsed:  5.7min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1024 out of 1024 | elapsed:  7.6min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1024 out of 1024 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9923362344818045 0.9706492786139482\n",
      "MSE = 27.165\n",
      "MAE = 2.405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9923362344818045, 0.9706492786139482)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfregressor = RandomForestRegressor(n_estimators=1024, random_state=0, verbose=1)\n",
    "full_pipeline = make_pipeline(col_adderdropper, colTransform, colNormalize, rfregressor)\n",
    "full_pipeline.set_params(coladderdropper__num_top_brands = 90)\n",
    "train_and_val(full_pipeline, X, y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# joblib.dump(full_pipeline, 'rf_1024.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
