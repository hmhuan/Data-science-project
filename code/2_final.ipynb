{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/cars/train_data.csv\", sep = \"\\t\", encoding='utf-8')\n",
    "test = pd.read_csv(\"../data/cars/test_data.csv\", sep = \"\\t\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['price']\n",
    "test_y = test['price']\n",
    "X = train.drop(['price'], axis = 1)\n",
    "test_X = test.drop(['price'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilabel Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, l):\n",
    "    if type(x) is list:\n",
    "        l.update(x)\n",
    "class MultilabelEncoding(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col_name):\n",
    "        self.col_name = col_name\n",
    "        self.type_list = set()\n",
    "    def fit(self, X_df, y=None):\n",
    "        types_sr = X_df[self.col_name].str.replace('[/+]', ' ').str.split()\n",
    "        types_sr.apply(f, args=(self.type_list,))\n",
    "        self.type_list = list(self.type_list)\n",
    "        return self\n",
    "    def transform(self, X_df, y=None):\n",
    "        transformed_df = X_df.copy()\n",
    "        for i in range(len(self.type_list)):\n",
    "            transformed_df[self.col_name + '_' + self.type_list[i]] = transformed_df[self.col_name].apply(lambda x: 1 if ((type(x) is str) and (self.type_list[i] in x)) else 0)\n",
    "        transformed_df.drop(self.col_name, axis=1, inplace=True)\n",
    "        return transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### col add and drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColAdderDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_top_brands = 10):\n",
    "        # TODO\n",
    "        self.num_top_brands = num_top_brands\n",
    "        self.dropped_cols = ['url', 'name', 'model', 'weightTotal', 'fuelType', 'vehicleTransmission', 'modelDate']\n",
    "    def fit(self, X_df, y=None):\n",
    "        brand_col = X_df.brand.str.extract(r'([a-zA-z]+)', expand=False)\n",
    "        self.brand_counts_ = brand_col.value_counts()\n",
    "        brands = list(self.brand_counts_.index)\n",
    "        self.top_brands_ = brands[:max(1, min(self.num_top_brands, len(brands)))]\n",
    "        return self\n",
    "    def transform(self, X_df, y=None):\n",
    "        df = X_df.copy()\n",
    "        brand_col = df.brand.str.extract(\"([a-zA-z]+)\", expand=False)\n",
    "        brand_col[~brand_col.isin(self.top_brands_)] = 'Others'\n",
    "        df[\"brand\"] = brand_col\n",
    "        df.drop(self.dropped_cols, axis=1, inplace=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_multi = ['vEfuelType', 'driveWheelConfiguration']\n",
    "cat_single = ['brand', 'eLabel', 'bodyType', 'vEengineType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_adderdropper = ColAdderDropper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['length',\n",
       "  'width',\n",
       "  'weight',\n",
       "  'emissionsCO2',\n",
       "  'numberOfForwardGears',\n",
       "  'roofLoad',\n",
       "  'fuelCapacity',\n",
       "  'fuelConsumption',\n",
       "  'speed',\n",
       "  'payload',\n",
       "  'trailerWeight',\n",
       "  'vEengineDisplacement',\n",
       "  'vEenginePower',\n",
       "  'torque'],\n",
       " 14)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = []\n",
    "for col in X.columns:\n",
    "    if (not col in cat_single) and (not col in cat_multi) and (not col in col_adderdropper.dropped_cols):\n",
    "        num_cols.append(col)\n",
    "        \n",
    "num_col_to_remove = ['height', 'numberOfAxles', 'numberOfDoors', 'seatingCapacity', 'cargoVolume',\n",
    "                    'accelerationTime']\n",
    "[num_cols.remove(x) for x in num_col_to_remove]\n",
    "num_cols, len(num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hàm train và validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_val(full_pipeline, train_X, train_y, val_X, val_y):\n",
    "    full_pipeline.fit(train_X, train_y);\n",
    "    #print(\"n_brands:\", len(col_adderdropper.top_brands_))\n",
    "    pred_y = full_pipeline.predict(val_X)\n",
    "    train_score = full_pipeline.score(train_X, train_y)\n",
    "    val_score = full_pipeline.score(val_X, val_y)\n",
    "    print(train_score, val_score)\n",
    "    print(\"MSE =\", np.round(np.mean((pred_y - val_y) ** 2), 3))\n",
    "    print(\"MAE =\", np.round(np.mean(np.abs(pred_y - val_y)), 3))\n",
    "    return train_score, val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### các pipeline cần thiết cho pipeline cho preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(strategy='mean') \n",
    "imp_mode = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "encoding = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "vEfuelType_encoder = MultilabelEncoding('vEfuelType')\n",
    "driveWheelConfig_encoder = MultilabelEncoding('driveWheelConfiguration')\n",
    "\n",
    "categorical_transformer = make_pipeline(imp_mode, encoding)\n",
    "\n",
    "colTransform = ColumnTransformer(transformers=[('numerical', imp_mean, num_cols),\\\n",
    "                                               ('categorical', categorical_transformer, cat_single),\n",
    "                                               ('vEfuelType', vEfuelType_encoder, ['vEfuelType']),\n",
    "                                               ('driveWheelConfig', driveWheelConfig_encoder, ['driveWheelConfiguration'])])\n",
    "\n",
    "colNormalize = StandardScaler()\n",
    "pca = PCA(30)\n",
    "\n",
    "preprocessing = make_pipeline(col_adderdropper, colTransform, colNormalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Full pipeline với MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 110.28410122\n",
      "Validation score: 0.922276\n",
      "Iteration 2, loss = 44.44261977\n",
      "Validation score: 0.927356\n",
      "Iteration 3, loss = 37.54884753\n",
      "Validation score: 0.941048\n",
      "Iteration 4, loss = 36.46500166\n",
      "Validation score: 0.927193\n",
      "Iteration 5, loss = 34.99357146\n",
      "Validation score: 0.937087\n",
      "Iteration 6, loss = 30.39187163\n",
      "Validation score: 0.947375\n",
      "Iteration 7, loss = 27.50362920\n",
      "Validation score: 0.949383\n",
      "Iteration 8, loss = 28.01421253\n",
      "Validation score: 0.957199\n",
      "Iteration 9, loss = 25.04107164\n",
      "Validation score: 0.956414\n",
      "Iteration 10, loss = 24.22103417\n",
      "Validation score: 0.955130\n",
      "Iteration 11, loss = 20.81094842\n",
      "Validation score: 0.957062\n",
      "Iteration 12, loss = 20.37327122\n",
      "Validation score: 0.956998\n",
      "Iteration 13, loss = 20.35389482\n",
      "Validation score: 0.960079\n",
      "Iteration 14, loss = 20.46053649\n",
      "Validation score: 0.946680\n",
      "Iteration 15, loss = 17.70876329\n",
      "Validation score: 0.934189\n",
      "Iteration 16, loss = 16.85773045\n",
      "Validation score: 0.945306\n",
      "Iteration 17, loss = 15.46220332\n",
      "Validation score: 0.950881\n",
      "Iteration 18, loss = 18.00517507\n",
      "Validation score: 0.958305\n",
      "Iteration 19, loss = 17.28871601\n",
      "Validation score: 0.956680\n",
      "Iteration 20, loss = 16.46672445\n",
      "Validation score: 0.959690\n",
      "Iteration 21, loss = 14.83514094\n",
      "Validation score: 0.963403\n",
      "Iteration 22, loss = 13.43316056\n",
      "Validation score: 0.955605\n",
      "Iteration 23, loss = 14.40578064\n",
      "Validation score: 0.955272\n",
      "Iteration 24, loss = 14.99638117\n",
      "Validation score: 0.957260\n",
      "Iteration 25, loss = 16.26078283\n",
      "Validation score: 0.962770\n",
      "Iteration 26, loss = 14.61888074\n",
      "Validation score: 0.965815\n",
      "Iteration 27, loss = 11.63346235\n",
      "Validation score: 0.953893\n",
      "Iteration 28, loss = 12.34632179\n",
      "Validation score: 0.964350\n",
      "Iteration 29, loss = 12.39956768\n",
      "Validation score: 0.966548\n",
      "Iteration 30, loss = 13.96756384\n",
      "Validation score: 0.960508\n",
      "Iteration 31, loss = 11.30698392\n",
      "Validation score: 0.962607\n",
      "Iteration 32, loss = 11.30973645\n",
      "Validation score: 0.966903\n",
      "Iteration 33, loss = 10.95947829\n",
      "Validation score: 0.962838\n",
      "Iteration 34, loss = 11.96378557\n",
      "Validation score: 0.949417\n",
      "Iteration 35, loss = 11.64617182\n",
      "Validation score: 0.966750\n",
      "Iteration 36, loss = 12.26242325\n",
      "Validation score: 0.967582\n",
      "Iteration 37, loss = 10.26445039\n",
      "Validation score: 0.964732\n",
      "Iteration 38, loss = 9.82757718\n",
      "Validation score: 0.958778\n",
      "Iteration 39, loss = 11.18954387\n",
      "Validation score: 0.962760\n",
      "Iteration 40, loss = 11.58181149\n",
      "Validation score: 0.966123\n",
      "Iteration 41, loss = 10.33112256\n",
      "Validation score: 0.964049\n",
      "Iteration 42, loss = 10.11736782\n",
      "Validation score: 0.967101\n",
      "Iteration 43, loss = 10.36983187\n",
      "Validation score: 0.965234\n",
      "Iteration 44, loss = 10.01127809\n",
      "Validation score: 0.969062\n",
      "Iteration 45, loss = 8.72861045\n",
      "Validation score: 0.968552\n",
      "Iteration 46, loss = 9.18869574\n",
      "Validation score: 0.967624\n",
      "Iteration 47, loss = 9.35116955\n",
      "Validation score: 0.969719\n",
      "Iteration 48, loss = 9.30492295\n",
      "Validation score: 0.961150\n",
      "Iteration 49, loss = 11.17095287\n",
      "Validation score: 0.969549\n",
      "Iteration 50, loss = 11.93046129\n",
      "Validation score: 0.968041\n",
      "Iteration 51, loss = 8.52180150\n",
      "Validation score: 0.967747\n",
      "Iteration 52, loss = 8.17559397\n",
      "Validation score: 0.967140\n",
      "Iteration 53, loss = 9.56765203\n",
      "Validation score: 0.970044\n",
      "Iteration 54, loss = 10.29870636\n",
      "Validation score: 0.968755\n",
      "Iteration 55, loss = 9.12274201\n",
      "Validation score: 0.967014\n",
      "Iteration 56, loss = 8.95709454\n",
      "Validation score: 0.969372\n",
      "Iteration 57, loss = 8.65220083\n",
      "Validation score: 0.971187\n",
      "Iteration 58, loss = 9.09092560\n",
      "Validation score: 0.968713\n",
      "Iteration 59, loss = 8.09088891\n",
      "Validation score: 0.968074\n",
      "Iteration 60, loss = 8.51181877\n",
      "Validation score: 0.967930\n",
      "Iteration 61, loss = 8.12740814\n",
      "Validation score: 0.967846\n",
      "Iteration 62, loss = 8.29927697\n",
      "Validation score: 0.970625\n",
      "Iteration 63, loss = 8.03014357\n",
      "Validation score: 0.964709\n",
      "Iteration 64, loss = 9.23549478\n",
      "Validation score: 0.963877\n",
      "Iteration 65, loss = 8.09252142\n",
      "Validation score: 0.961161\n",
      "Iteration 66, loss = 9.73147020\n",
      "Validation score: 0.968539\n",
      "Iteration 67, loss = 8.02427290\n",
      "Validation score: 0.969217\n",
      "Iteration 68, loss = 7.68424506\n",
      "Validation score: 0.971972\n",
      "Iteration 69, loss = 7.93634123\n",
      "Validation score: 0.970252\n",
      "Iteration 70, loss = 8.78306456\n",
      "Validation score: 0.970319\n",
      "Iteration 71, loss = 8.05681668\n",
      "Validation score: 0.969238\n",
      "Iteration 72, loss = 7.77932300\n",
      "Validation score: 0.968411\n",
      "Iteration 73, loss = 7.59119103\n",
      "Validation score: 0.971940\n",
      "Iteration 74, loss = 7.37055477\n",
      "Validation score: 0.968548\n",
      "Iteration 75, loss = 7.81831473\n",
      "Validation score: 0.970134\n",
      "Iteration 76, loss = 7.42969104\n",
      "Validation score: 0.971360\n",
      "Iteration 77, loss = 7.53302292\n",
      "Validation score: 0.971287\n",
      "Iteration 78, loss = 8.61365213\n",
      "Validation score: 0.971453\n",
      "Iteration 79, loss = 7.66024667\n",
      "Validation score: 0.967994\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.9846814518215354 0.9758296985939665\n",
      "MSE = 22.37\n",
      "MAE = 2.472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9846814518215354, 0.9758296985939665)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_n_brands = 80\n",
    "mlpregressor = MLPRegressor(hidden_layer_sizes=(256, 512, 512, 256, ), solver='adam', learning_rate='adaptive'\\\n",
    "                            ,random_state=0, max_iter=500, early_stopping=True, verbose=1)\n",
    "full_pipeline = make_pipeline(col_adderdropper, colTransform, colNormalize, mlpregressor)\n",
    "full_pipeline.set_params(coladderdropper__num_top_brands=best_n_brands)\n",
    "train_and_val(full_pipeline, train, y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../resource/nn_80_final.pkl']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(full_pipeline, '../resource/nn_80_final.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full pipeline với RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 256 out of 256 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 256 out of 256 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 256 out of 256 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9922015113377136 0.9706421257451378\n",
      "MSE = 27.172\n",
      "MAE = 2.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 256 out of 256 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9922015113377136, 0.9706421257451378)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfregressor = RandomForestRegressor(n_estimators=256, random_state=0, verbose=1)\n",
    "full_pipeline = make_pipeline(col_adderdropper, colTransform, colNormalize, rfregressor)\n",
    "full_pipeline.set_params(coladderdropper__num_top_brands = 90)\n",
    "train_and_val(full_pipeline, X, y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# joblib.dump(full_pipeline, 'rf_1024.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.set_params(coladderdropper__num_top_brands=best_n_brands)\n",
    "X_preprocessed = preprocessing.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {'n_estimators': [100, 200, 400, 600, 800],\n",
    "              'max_depth': list(range(1,10))}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingRegressor(learning_rate=0.1, min_samples_split=500, min_samples_leaf=50,\n",
    "                                                               max_features='sqrt',subsample=0.8,verbose = 0), \n",
    "                        param_grid = param_test1, scoring='r2',n_jobs=4,iid=False, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/norm/hoai_workspace/hoai_env/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=3,\n",
       "                                                 max_features='sqrt',\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=50,\n",
       "                                                 min_samples_split=500,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 n_iter_no_change=None,\n",
       "                                                 presort='auto',\n",
       "                                                 random_state=None,\n",
       "                                                 subsample=0.8, tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid=False, n_jobs=4,\n",
       "             param_grid={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'n_estimators': [100, 200, 400, 600, 800]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.fit(X_preprocessed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'n_estimators': 800}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingRegressor(learning_rate=0.1, min_samples_split=500, min_samples_leaf=50,max_depth=9,\n",
    "                                n_estimators=800, max_features='sqrt',subsample=0.8, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9759913902927685 0.9726224630872703\n",
      "MSE = 25.339\n",
      "MAE = 2.771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9759913902927685, 0.9726224630872703)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline = make_pipeline(col_adderdropper, colTransform, colNormalize, gbm)\n",
    "full_pipeline.set_params(coladderdropper__num_top_brands = 90)\n",
    "train_and_val(full_pipeline, X, y, test_X, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
