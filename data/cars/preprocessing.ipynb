{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # seaborn là thư viện được xây trên matplotlib, giúp việc visualization đỡ khổ hơn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df = pd.read_csv(\"cars_dataset.csv\", sep = \"\\t\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Chuyển đổi dữ liệu từ dữ liệu thô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['price', 'length', 'height', 'width', 'weight', 'weightTotal', 'emissionsCO2', 'numberOfAxles',\n",
    "            'numberOfDoors', 'numberOfForwardGears', 'seatingCapacity', 'cargoVolume', 'roofLoad', \n",
    "            'accelerationTime', 'fuelCapacity', 'fuelConsumption', 'speed', 'payload', 'trailerWeight', \n",
    "            'vEengineDisplacement', 'vEenginePower', 'torque']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = []\n",
    "for col in cars_df.columns:\n",
    "    if not (col in num_cols):\n",
    "        cat_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(num_cols), len(cat_cols))\n",
    "print(num_cols, '\\n', cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xử lý các cột dữ liệu số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy ra df để xư lý\n",
    "df = cars_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fucntion convert cac thuoc tinh khac\n",
    "def cvtFloat(x):\n",
    "    if type(x) == str:\n",
    "        temp = x.replace(',', '.').split()[0]\n",
    "    else:\n",
    "        temp = x\n",
    "    val = None\n",
    "    try:\n",
    "        val = float(temp)\n",
    "    except ValueError:\n",
    "        return val\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in num_cols:\n",
    "    if el != 'cargoVolume':\n",
    "        print(el)\n",
    "        df[el] = df[el].apply(cvtFloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm xử lý riêng cho cargoVolume\n",
    "def cvtFloat_cargoVolume(x):\n",
    "    temp = x.split()[0]\n",
    "    temp = temp.replace('-', ' ')\n",
    "    temp = temp.split()\n",
    "    if len(temp) > 0:\n",
    "        temp = temp[-1]\n",
    "    else:\n",
    "        temp = x\n",
    "    val = None\n",
    "    try:\n",
    "        val = float(temp)\n",
    "    except ValueError:\n",
    "        return val\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cargoVolume'] = df['cargoVolume'].apply(cvtFloat_cargoVolume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_cols].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xử lý các cột dữ liệu categorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in cat_cols[:]:\n",
    "    print(cat, len(cars_df[cat].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Có thể loại bỏ cột vehicleTransmission vì chỉ có 1 giá trị, không có ý nghĩa trong việc học.\n",
    "* Cột fuelType và vEfuelType là giống nhau (do quá trình crawl nhóm không để ý), có thể drop cột fuelType.\n",
    "* Các cột url, name, model có nhiều ý nghĩa, nên có thể loại bỏ.\n",
    "* brand có thể xét vì có tới 89 giá trị (có khả năng sẽ có ý nghĩa với các brand có giá trị cao), modelDate cần xem xét.\n",
    "\n",
    "**=> Số cột còn lại là: eLabel (9), bodyType (11), driveWheelConfiguration (6), vEengineType (4), vEfuelType (11).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chuẩn hóa cột modelDate\n",
    "def norm_modelDate(x):\n",
    "    if (x == 0):\n",
    "        return None\n",
    "    else:\n",
    "        return str(x)\n",
    "df['modelDate'] = df['modelDate'].apply(norm_modelDate)\n",
    "df['modelDate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['driveWheelConfiguration'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['price', 'driveWheelConfiguration']].groupby('driveWheelConfiguration').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bodyType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['eLabel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vEengineType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vEfuelType'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cột driveWheelConfiguration không có giá trị lỗi ('N.A.', '-', ...)\n",
    "* Các cột bodyType, vEengineType, vEfuelType có chứa nan (đã được xử lý).\n",
    "* Cột eLabel có chứa các giá trị lỗi, cần được chuẩn hóa. Sau khi chuẩn hóa, dòng thiếu dữ liệu quá nhiều nên cần loại bỏ khi qua bước xử lý."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_eLabel(x):\n",
    "    if (x == 'N.A.' or x == '-'):\n",
    "        return None\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['eLabel'] = df['eLabel'].apply(norm_eLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat_cols].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lưu ra file để tiện xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"cars_preprocessed_undrop.csv\", sep = \"\\t\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori = pd.read_csv(\"train_data.csv\", sep = \"\\t\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ori.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "X = df.drop(['price'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin copy\n",
    "X_ori = X.copy()\n",
    "y_ori = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60472, 15118)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X), len(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['petrol', 'diesel', 'LPG', 'bio-ethanol', nan, 'natural gas',\n",
       "       'benzine', 'aardgas / petrol', 'aardgas', 'LPG / petrol',\n",
       "       'petrol / bio-ethanol'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['vEfuelType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LPG',\n",
       " 'aardgas',\n",
       " 'benzine',\n",
       " 'bio-ethanol',\n",
       " 'diesel',\n",
       " 'gas',\n",
       " 'natural',\n",
       " 'petrol'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_list = set()\n",
    "\n",
    "    \n",
    "type_sr = temp['vEfuelType'].str.replace('[/+]', ' ').str.split()\n",
    "def func(x):\n",
    "    if type(x) is list:\n",
    "        type_list.update(x)\n",
    "type_sr.apply(func)\n",
    "type_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tạo pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilabel Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, l):\n",
    "    if type(x) is list:\n",
    "        l.update(x)\n",
    "class MultilabelEncoding(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col_name):\n",
    "        self.col_name = col_name\n",
    "        self.type_list = set()\n",
    "    def fit(self, X_df, y=None):\n",
    "        types_sr = X_df[self.col_name].str.replace('[/+]', ' ').str.split()\n",
    "        types_sr.apply(f, args=(self.type_list,))\n",
    "        self.type_list = list(self.type_list)\n",
    "        return self\n",
    "    def transform(self, X_df, y=None):\n",
    "        transformed_df = X_df.copy()\n",
    "        for i in range(len(self.type_list)):\n",
    "            transformed_df[self.col_name + '_' + self.type_list[i]] = transformed_df[self.col_name].apply(lambda x: 1 if ((type(x) is str) and (self.type_list[i] in x)) else 0)\n",
    "        transformed_df.drop(self.col_name, axis=1, inplace=True)\n",
    "        return transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### col add and drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColAdderDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_top_brands = 10):\n",
    "        # TODO\n",
    "        self.num_top_brands = num_top_brands\n",
    "        self.dropped_cols = ['url', 'name', 'model', 'weightTotal', 'fuelType', 'vehicleTransmission', 'modelDate']\n",
    "    def fit(self, X_df, y=None):\n",
    "        brand_col = X_df.brand.str.extract(r'([a-zA-z]+)', expand=False)\n",
    "        self.brand_counts_ = brand_col.value_counts()\n",
    "        brands = list(self.brand_counts_.index)\n",
    "        self.top_brands_ = brands[:max(1, min(self.num_top_brands, len(brands)))]\n",
    "        return self\n",
    "    def transform(self, X_df, y=None):\n",
    "        df = X_df.copy()\n",
    "        brand_col = df.brand.str.extract(\"([a-zA-z]+)\", expand=False)\n",
    "        brand_col[~brand_col.isin(self.top_brands_)] = 'Others'\n",
    "        df[\"brand\"] = brand_col\n",
    "        df.drop(self.dropped_cols, axis=1, inplace=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_multi = ['vEfuelType', 'driveWheelConfiguration']\n",
    "cat_single = ['brand', 'eLabel', 'bodyType', 'vEengineType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_adderdropper = ColAdderDropper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = []\n",
    "for col in X.columns:\n",
    "    if (not col in cat_single) and (not col in cat_multi) and (not col in col_adderdropper.dropped_cols):\n",
    "        num_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_cols), len(cat_single), len(cat_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pipeline cho preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(strategy='mean') \n",
    "imp_mode = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "encoding = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "vEfuelType_encoder = MultilabelEncoding('vEfuelType')\n",
    "driveWheelConfig_encoder = MultilabelEncoding('driveWheelConfiguration')\n",
    "\n",
    "categorical_transformer = make_pipeline(imp_mode, encoding)\n",
    "\n",
    "colTransform = ColumnTransformer(transformers=[('numerical', imp_mean, num_cols),\\\n",
    "                                               ('categorical', categorical_transformer, cat_single),\n",
    "                                               ('vEfuelType', vEfuelType_encoder, ['vEfuelType']),\n",
    "                                               ('driveWheelConfig', driveWheelConfig_encoder, ['driveWheelConfiguration'])])\n",
    "\n",
    "colNormalize = StandardScaler()\n",
    "\n",
    "#preprocessing = make_pipeline(col_adderdropper, colTransform, colNormalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train và validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_val(full_pipeline, train_X, train_y, val_X, val_y):\n",
    "    full_pipeline.fit(train_X, train_y);\n",
    "    #print(\"n_brands:\", len(col_adderdropper.top_brands_))\n",
    "    pred_y = full_pipeline.predict(val_X)\n",
    "    train_score = full_pipeline.score(train_X, train_y)\n",
    "    val_score = full_pipeline.score(val_X, val_y)\n",
    "    print(train_score, val_score)\n",
    "    print(\"MSE =\", np.round(np.mean((pred_y - val_y) ** 2), 3))\n",
    "    print(\"MAE =\", np.round(np.mean(np.abs(pred_y - val_y)), 3))\n",
    "    return train_score, val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full pipeline với MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 135.22053926\n",
      "Iteration 2, loss = 47.06151951\n",
      "Iteration 3, loss = 40.72841616\n",
      "Iteration 4, loss = 37.59122228\n",
      "Iteration 5, loss = 34.09809402\n",
      "Iteration 6, loss = 32.26771227\n",
      "Iteration 7, loss = 32.08256134\n",
      "Iteration 8, loss = 29.97067353\n",
      "Iteration 9, loss = 28.12729006\n",
      "Iteration 10, loss = 24.30484254\n",
      "Iteration 11, loss = 28.13428605\n",
      "Iteration 12, loss = 22.79060809\n",
      "Iteration 13, loss = 23.23534896\n",
      "Iteration 14, loss = 24.95457520\n",
      "Iteration 15, loss = 18.42730958\n",
      "Iteration 16, loss = 23.32014577\n",
      "Iteration 17, loss = 17.62998306\n",
      "Iteration 18, loss = 17.64785341\n",
      "Iteration 19, loss = 17.54144185\n",
      "Iteration 20, loss = 16.37988419\n",
      "Iteration 21, loss = 16.30041557\n",
      "Iteration 22, loss = 15.92875516\n",
      "Iteration 23, loss = 14.66517204\n",
      "Iteration 24, loss = 14.75445453\n",
      "Iteration 25, loss = 17.70168423\n",
      "Iteration 26, loss = 14.82008038\n",
      "Iteration 27, loss = 13.50990349\n",
      "Iteration 28, loss = 12.81675808\n",
      "Iteration 29, loss = 11.77376615\n",
      "Iteration 30, loss = 11.90233630\n",
      "Iteration 31, loss = 12.97533723\n",
      "Iteration 32, loss = 12.97669269\n",
      "Iteration 33, loss = 11.50888322\n",
      "Iteration 34, loss = 11.30484982\n",
      "Iteration 35, loss = 13.18589760\n",
      "Iteration 36, loss = 14.39743104\n",
      "Iteration 37, loss = 11.35737435\n",
      "Iteration 38, loss = 10.91445393\n",
      "Iteration 39, loss = 11.27186197\n",
      "Iteration 40, loss = 11.39216072\n",
      "Iteration 41, loss = 12.26758355\n",
      "Iteration 42, loss = 10.62625714\n",
      "Iteration 43, loss = 11.06007683\n",
      "Iteration 44, loss = 10.72528379\n",
      "Iteration 45, loss = 9.32684363\n",
      "Iteration 46, loss = 9.65855218\n",
      "Iteration 47, loss = 10.64174048\n",
      "Iteration 48, loss = 9.93785971\n",
      "Iteration 49, loss = 12.49940920\n",
      "Iteration 50, loss = 10.75578057\n",
      "Iteration 51, loss = 10.46569958\n",
      "Iteration 52, loss = 9.72709443\n",
      "Iteration 53, loss = 10.14523281\n",
      "Iteration 54, loss = 9.55585382\n",
      "Iteration 55, loss = 9.86599326\n",
      "Iteration 56, loss = 10.99002500\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.9801582900562297 0.7180321752236754\n",
      "MSE = 255.468\n",
      "MAE = 2.731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9801582900562297, 0.7180321752236754)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpregressor = MLPRegressor(hidden_layer_sizes=(128, 256, 256, 128, ), solver='adam', learning_rate='adaptive'\\\n",
    "                            ,random_state=0, max_iter=500, early_stopping=False, verbose=1)\n",
    "\n",
    "# preprocessing.set_params(coladderdropper__num_top_brands = 100)\n",
    "\n",
    "full_pipeline = make_pipeline(col_adderdropper, colTransform, colNormalize, mlpregressor)\n",
    "\n",
    "full_pipeline.set_params(coladderdropper__num_top_brands = 100)\n",
    "\n",
    "train_and_val(full_pipeline, train_X, train_y, val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_adderdropper.top_brands_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpregressor = MLPRegressor(hidden_layer_sizes=(16, 32, 64, 64, 32, 16, ), solver='adam', learning_rate='adaptive'\\\n",
    "                            ,random_state=0, max_iter=500, early_stopping=True, verbose=0)\n",
    "\n",
    "full_pipeline = make_pipeline(col_adderdropper, colTransform, colNormalize, mlpregressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_brands: 10\n",
      "0.9288349180654218 0.7038676272867647\n",
      "MSE = 268.301\n",
      "MAE = 4.181\n",
      "\n",
      "n_brands: 15\n",
      "0.9743537993693123 0.6729681857059386\n",
      "MSE = 296.297\n",
      "MAE = 3.327\n",
      "\n",
      "n_brands: 20\n",
      "0.9707413272311217 0.5961798633177005\n",
      "MSE = 365.868\n",
      "MAE = 3.479\n",
      "\n",
      "n_brands: 25\n",
      "0.9661561424118765 0.6930479393998731\n",
      "MSE = 278.104\n",
      "MAE = 3.573\n",
      "\n",
      "n_brands: 30\n",
      "0.9685471320405159 0.5422445951124799\n",
      "MSE = 414.734\n",
      "MAE = 3.506\n",
      "\n",
      "n_brands: 35\n",
      "0.9708504913781262 0.34738018365784296\n",
      "MSE = 591.285\n",
      "MAE = 3.48\n",
      "\n",
      "n_brands: 40\n",
      "0.9673899866376643 0.6248246909915811\n",
      "MSE = 339.915\n",
      "MAE = 3.537\n",
      "\n",
      "n_brands: 45\n",
      "0.9723446048487259 0.5886804806431734\n",
      "MSE = 372.663\n",
      "MAE = 3.559\n",
      "\n",
      "n_brands: 50\n",
      "0.9726382009578769 0.36684338926492666\n",
      "MSE = 573.651\n",
      "MAE = 3.441\n",
      "\n",
      "n_brands: 55\n",
      "0.9622277134541068 0.7792741241967922\n",
      "MSE = 199.982\n",
      "MAE = 3.455\n",
      "\n",
      "n_brands: 60\n",
      "0.9663933914430549 0.4550759592660548\n",
      "MSE = 493.711\n",
      "MAE = 3.58\n",
      "\n",
      "n_brands: 65\n",
      "0.9749038787644124 0.6637803958545977\n",
      "MSE = 304.621\n",
      "MAE = 3.208\n",
      "\n",
      "n_brands: 70\n",
      "0.9732689744269162 0.5785846686747914\n",
      "MSE = 381.81\n",
      "MAE = 3.272\n",
      "\n",
      "n_brands: 75\n",
      "0.9477889749402628 0.8257992728772184\n",
      "MSE = 157.829\n",
      "MAE = 3.65\n",
      "\n",
      "n_brands: 80\n",
      "0.9642713206373889 0.7961426267814511\n",
      "MSE = 184.698\n",
      "MAE = 3.413\n",
      "\n",
      "n_brands: 85\n",
      "0.9705505965671651 0.8305348894341249\n",
      "MSE = 153.538\n",
      "MAE = 3.237\n",
      "\n",
      "n_brands: 87\n",
      "0.9470223201261853 0.938897312093923\n",
      "MSE = 55.36\n",
      "MAE = 3.603\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finish!'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpregressor = MLPRegressor(hidden_layer_sizes=(16, 32, 64, 64, 32, 16, ), solver='adam', learning_rate='adaptive'\\\n",
    "                            ,random_state=0, max_iter=500, early_stopping=True)\n",
    "for n_brands in range(10, 95, 5):\n",
    "    print('.')\n",
    "    full_pipeline.set_params(coladderdropper__num_top_brands=n_brands)\n",
    "    train_and_val(full_pipeline, train_X, train_y, val_X, val_y)\n",
    "    print()\n",
    "'Finish!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full pipeline với RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfregressor = RandomForestRegressor(n_estimators=512, random_state=0, verbose=1)\n",
    "full_pipeline = make_pipeline(preprocessing, rfregressor)\n",
    "train_and_val(full_pipeline, train_X, train_y, val_X, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chọn hyper-parameter tùy vào regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "val_scores = []\n",
    "alphas = [0.1, 1, 10, 100, 1000]\n",
    "best_val_score = -float('inf'); best_alpha = None;\n",
    "for alpha in alphas:\n",
    "    full_pipeline.set_params(mlpregressor__alpha=alpha)\n",
    "    full_pipeline.fit(train_X, train_y)\n",
    "    full_pipeline.predict(val_X)\n",
    "    train_score = full_pipeline.score(train_X, train_y)\n",
    "    val_score = full_pipeline.score(val_X, val_y)\n",
    "    train_scores.append(train_score)\n",
    "    val_scores.append(val_score)\n",
    "    if best_val_score < val_score:\n",
    "        best_val_score = val_score\n",
    "        best_alpha = alpha\n",
    "'Finish!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_pipeline.set_params(mlpregressor__alpha=best_alpha)\n",
    "pred_y = full_pipeline.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(pred_y - test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(pred_y - test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((pred_y - test_y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((pred_y - test_y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
